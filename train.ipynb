{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# vAGI L-KAN train tren Google Colab (NVIDIA T4)\n",
        "\n",
        "Notebook nay duoc thiet ke de train `vagi-kernel` binary `train_lkan` tren Colab GPU.\n",
        "\n",
        "## Tham khao chinh\n",
        "- Candle installation guide: https://huggingface.github.io/candle/guide/installation.html\n",
        "- Candle CUDA feature flags (crate): https://docs.rs/crate/candle-core/0.8.4/features\n",
        "- Rust toolchain (rustup): https://rustup.rs/\n",
        "- TinyShakespeare corpus: https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "\n",
        "## Output\n",
        "- Checkpoint se duoc luu tai: `models/lkan-genesis.safetensors`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "import subprocess\n",
        "import sys\n",
        "import urllib.request\n",
        "\n",
        "def run(cmd: str, check: bool = True):\n",
        "    print(f\"$ {cmd}\")\n",
        "    return subprocess.run(cmd, shell=True, check=check, text=True)\n",
        "\n",
        "print(\"Python:\", sys.version)\n",
        "run(\"nvidia-smi\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Neu ban da upload source vao /content/vagi thi giu nguyen.\n",
        "# Neu chua co source, cap nhat REPO_URL roi chay cell clone o duoi.\n",
        "REPO_URL = \"https://github.com/<YOUR_GITHUB_USER>/vagi.git\"\n",
        "BRANCH = \"main\"\n",
        "WORKDIR = pathlib.Path(\"/content/vagi\")\n",
        "\n",
        "# Cau hinh train khuyen nghi cho T4 (vua toc do, vua on dinh).\n",
        "MODEL_OUT = \"models/lkan-genesis.safetensors\"\n",
        "TRAIN_STEPS = 5_000\n",
        "BATCH_SIZE = 32\n",
        "SEQ_LEN = 64\n",
        "HIDDEN_DIM = 128\n",
        "\n",
        "print(\"WORKDIR:\", WORKDIR)\n",
        "print(\"MODEL_OUT:\", MODEL_OUT)\n",
        "print(\"TRAIN_STEPS:\", TRAIN_STEPS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not WORKDIR.exists():\n",
        "    if \"<YOUR_GITHUB_USER>\" in REPO_URL:\n",
        "        raise ValueError(\"Hay cap nhat REPO_URL hoac upload source vao /content/vagi truoc khi chay.\")\n",
        "    run(f\"git clone --depth 1 --branch {BRANCH} {REPO_URL} {WORKDIR}\")\n",
        "\n",
        "os.chdir(WORKDIR)\n",
        "run(\"git rev-parse --short HEAD\", check=False)\n",
        "print(\"Current dir:\", pathlib.Path.cwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run(\"apt-get -y update\")\n",
        "run(\"apt-get -y install build-essential pkg-config libssl-dev curl git\")\n",
        "\n",
        "if not pathlib.Path(\"/root/.cargo/bin/rustup\").exists():\n",
        "    run(\"curl https://sh.rustup.rs -sSf | sh -s -- -y --profile minimal\")\n",
        "\n",
        "os.environ[\"PATH\"] = f\"/root/.cargo/bin:{os.environ['PATH']}\"\n",
        "run(\"rustup default stable\")\n",
        "run(\"rustc --version\")\n",
        "run(\"cargo --version\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cau hinh CUDA env cho Colab.\n",
        "os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda\"\n",
        "os.environ[\"PATH\"] = f\"/usr/local/cuda/bin:{os.environ['PATH']}\"\n",
        "os.environ[\"LD_LIBRARY_PATH\"] = f\"/usr/local/cuda/lib64:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
        "\n",
        "run(\"which nvcc\", check=False)\n",
        "run(\"nvcc --version\", check=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_path = WORKDIR / \"data\" / \"input.txt\"\n",
        "data_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if not data_path.exists():\n",
        "    url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "    print(\"Downloading dataset from:\", url)\n",
        "    urllib.request.urlretrieve(url, data_path)\n",
        "\n",
        "print(\"Dataset:\", data_path)\n",
        "print(\"Size (bytes):\", data_path.stat().st_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Patch source de:\n",
        "# 1) Bat CUDA cho candle-core.\n",
        "# 2) Dung Device::new_cuda(0) (fallback CPU neu khong co CUDA).\n",
        "# 3) Dong bo train config de checkpoint co the load boi runtime hien tai.\n",
        "\n",
        "kernel_cargo = WORKDIR / \"kernel\" / \"Cargo.toml\"\n",
        "cargo_text = kernel_cargo.read_text(encoding=\"utf-8\")\n",
        "\n",
        "dep_re = re.compile(r'^candle-core\\s*=\\s*(.+)$', re.MULTILINE)\n",
        "m = dep_re.search(cargo_text)\n",
        "if not m:\n",
        "    raise RuntimeError(\"Khong tim thay dependency candle-core trong kernel/Cargo.toml\")\n",
        "\n",
        "current_line = m.group(0)\n",
        "if 'features = [\"cuda\"]' not in current_line:\n",
        "    ver_match = re.search(r'version\\s*=\\s*\"([^\\\"]+)\"', current_line)\n",
        "    if not ver_match:\n",
        "        ver_match = re.search(r'\"([^\\\"]+)\"', current_line)\n",
        "    if not ver_match:\n",
        "        raise RuntimeError(\"Khong doc duoc version tu candle-core line: \" + current_line)\n",
        "    ver = ver_match.group(1)\n",
        "    new_line = f'candle-core = {{ version = \"{ver}\", features = [\"cuda\"] }}'\n",
        "    cargo_text = cargo_text.replace(current_line, new_line)\n",
        "    kernel_cargo.write_text(cargo_text, encoding=\"utf-8\")\n",
        "    print(\"Patched kernel/Cargo.toml:\", new_line)\n",
        "else:\n",
        "    print(\"kernel/Cargo.toml da bat CUDA cho candle-core:\", current_line)\n",
        "\n",
        "train_rs = WORKDIR / \"kernel\" / \"src\" / \"bin\" / \"train_lkan.rs\"\n",
        "src = train_rs.read_text(encoding=\"utf-8\")\n",
        "\n",
        "def replace_const(text: str, name: str, value: str) -> str:\n",
        "    pattern = rf'const {name}: [^=]+ = [^;]+;'\n",
        "    repl = f'const {name}: usize = {value};'\n",
        "    if name == \"OUTPUT_PATH\":\n",
        "        repl = f'const OUTPUT_PATH: &str = \"{value}\";'\n",
        "    new_text, n = re.subn(pattern, repl, text, count=1)\n",
        "    if n == 0:\n",
        "        raise RuntimeError(f\"Khong tim thay const {name} trong train_lkan.rs\")\n",
        "    return new_text\n",
        "\n",
        "src = replace_const(src, \"OUTPUT_PATH\", MODEL_OUT)\n",
        "src = replace_const(src, \"BATCH_SIZE\", str(BATCH_SIZE))\n",
        "src = replace_const(src, \"SEQ_LEN\", str(SEQ_LEN))\n",
        "src = replace_const(src, \"TRAIN_STEPS\", str(TRAIN_STEPS))\n",
        "\n",
        "src = src.replace(\"hidden_dim: 192,\", f\"hidden_dim: {HIDDEN_DIM},\")\n",
        "src = src.replace(\"in_dim: 192,\", f\"in_dim: {HIDDEN_DIM},\")\n",
        "src = src.replace(\"hidden_dim: 192,\", f\"hidden_dim: {HIDDEN_DIM},\")\n",
        "src = src.replace(\"out_dim: 192,\", f\"out_dim: {HIDDEN_DIM},\")\n",
        "\n",
        "if \"Device::new_cuda(0)\" not in src:\n",
        "    cpu_line = \"let device = Device::Cpu;\"\n",
        "    cuda_block = \"\"\"let device = match Device::new_cuda(0) {\n",
        "        Ok(dev) => {\n",
        "            println!(\\\"using CUDA device 0\\\");\n",
        "            dev\n",
        "        }\n",
        "        Err(err) => {\n",
        "            println!(\\\"CUDA unavailable ({err}), fallback to CPU\\\");\n",
        "            Device::Cpu\n",
        "        }\n",
        "    };\"\"\"\n",
        "    if cpu_line not in src:\n",
        "        raise RuntimeError(\"Khong tim thay `let device = Device::Cpu;` de patch\")\n",
        "    src = src.replace(cpu_line, cuda_block)\n",
        "\n",
        "train_rs.write_text(src, encoding=\"utf-8\")\n",
        "print(\"Patched:\", train_rs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(WORKDIR)\n",
        "os.environ.setdefault(\"CARGO_BUILD_JOBS\", \"2\")\n",
        "\n",
        "# Build + train (release). Log se in loss theo train_lkan.rs.\n",
        "run(\"cargo run -p vagi-kernel --release --bin train_lkan\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint = WORKDIR / MODEL_OUT\n",
        "if not checkpoint.exists():\n",
        "    raise FileNotFoundError(f\"Khong tim thay checkpoint: {checkpoint}\")\n",
        "\n",
        "print(\"Checkpoint:\", checkpoint)\n",
        "print(\"Size (MB):\", round(checkpoint.stat().st_size / (1024 * 1024), 2))\n",
        "print(\"Done.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
